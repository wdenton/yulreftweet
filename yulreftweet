#!/usr/bin/env ruby
# -*- coding: utf-8 -*-

# This file is part of yulreftweet.
#
# yulreftweet is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# yulreftweet is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with yulreftweet.  If not, see <http://www.gnu.org/licenses/>.
#
# Copyright 2013 William Denton

# CONFIGURING
#
# Configuration details are set in the file config.json.
# Make a copy of config.json.example and edit it.

require 'json'
require 'open-uri'
require 'cgi'
require 'csv'
require 'logger'
require 'optparse'

require 'rubygems'
require 'twitter'

options = {}
options[:verbose] = false
options[:notweet] = false
OptionParser.new do |opts|
  opts.banner = "Usage: yulreftweet [--notweet] [--verbose]"
  opts.on("--notweet", "Do not actually tweet anything") { options[:notweet] = true }
  opts.on("--verbose", "Be verbose") { options[:verbose] = true }
end.parse!

logger = Logger.new(STDOUT)
if options[:verbose]
  logger.level = Logger::DEBUG
else
  logger.level = Logger::INFO
end

if options[:notweet]
  logger.info "--notweet specified; no tweeting will happen"
end

settings = {}

data_url = "http://www.library.yorku.ca/libstats/reportReturn.do?&library_id=&location_id=&report_id=DataCSVReport"

t_end   = Time.now
t_start = t_end - 5*60 # Five minutes ago
# t_start = t_end - 24*60*60 # One day ago (lots of results for testing)

ugly_date_format = "%m/%d/%y %l:%M %p"
 
end_time = t_end.strftime(ugly_date_format)
start_time = t_start.strftime(ugly_date_format)

tweet_csv_url = data_url + "&date1=#{CGI.escape(start_time)}&date2=#{CGI.escape(end_time)}"

logger.debug "Start: #{t_start.strftime("%F %R")}. End: #{t_end.strftime("%F %R")}."
logger.debug "CSV data URL: #{tweet_csv_url}"

begin
  settings = JSON.parse(File.read("config.json"))
rescue Exception => e
  STDERR.puts "No readable config.json settings file: #{e}"
  exit
end

Twitter.configure do |config|
  config.consumer_key       = settings["consumer_key"]
  config.consumer_secret    = settings["consumer_secret"]
  config.oauth_token        = settings["access_token"]
  config.oauth_token_secret = settings["access_token_secret"]
end

begin
  open(tweet_csv_url, "Cookie" => "login=#{settings["login_cookie"]}") do |f|

    unless f.status[0] == "200"
      logger.warn "Could not download data: status #{f.status}"
    else
      data = f.read
      if data == "\n"
        # LibStats returns a newline if there is no data ... inelegant, but we can deal with it.
        logger.info "Questions: 0"
      else
        csv = CSV.parse(data, {:headers => true, :header_converters => :symbol})
        # Silently drop activity at the Scott info desk, which is too busy
        # and would overwhelm Twitter.
        csv.delete_if {|row| row[:library_name] == "Scott Information"}

        if csv.size > 0
          delay = (300 / tweets_to_make).floor - 5
          logger.info "Questions: #{csv.size}"
          logger.debug "Delay: #{delay} seconds)"

          csv.each do |row|
            # Post one tweet for each question, at a leisurely pace
            type = row[:question_type][0,1].to_i # Will be [1..5]
            type_string = "■ " * type + "□ " * (5 - type)
            tweet = "#{row[:library_name]} #{type_string} #{row[:time_spent]} (#{row[:question_id]})"
            logger.debug tweet
            unless options[:notweet]
              begin
                Twitter.update(tweet)
              rescue Exception => e
                logger.error "Error tweeting (#{tweet}): #{e}"
              end
              sleep delay
              # TODO No need to sleep after last tweet; stop doing this
            end
          end

          logger.close      

        end
      end
    end
  end

rescue Exception => e
  logger.warn "Could not download data: #{e}"
end
